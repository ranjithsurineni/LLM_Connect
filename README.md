# ğŸ¤– Multi-Provider LLM Chatbot

A **Streamlit-based conversational AI application** designed to interface with leading large language model (LLM) APIs including **OpenAI**, **OpenRouter**, and **Hugging Face**. This application allows users to securely plug in their own API keys, select models dynamically, and engage in rich, contextual chatbot conversations â€” all through a seamless, privacy-conscious interface.

---

## ğŸš€ Features

- âœ… **Supports multiple AI providers** (OpenAI, OpenRouter, Hugging Face)
- ğŸ” **API-key protected**, no backend storage, secure session-based access
- ğŸ§  **Prompt Engineering Guide** tab with reusable examples
- ğŸ’¬ Real-time chatbot experience with sticky chat input
- ğŸ“¤ **Export chat history** (Markdown / JSON)
- ğŸ“‹ **Copy-to-clipboard** for AI responses
- ğŸ§¹ **Clear chat history** option
- ğŸ§© Modular code structure for easy integration & extension

---

## ğŸŒ Supported Providers & Models

| Provider | Example Models | Get API Key |
|---------|----------------|-------------|
| **OpenAI** | `gpt-3.5-turbo`, `gpt-4` | [ğŸ”— openai.com](https://platform.openai.com/account/api-keys) |
| **OpenRouter** | `anthropic/claude-3-opus`, `mistralai/mixtral-8x7b` | [ğŸ”— openrouter.ai](https://openrouter.ai) |
| **Hugging Face** | `mistralai/Mistral-7B-Instruct`, `tiiuae/falcon-7b` | [ğŸ”— huggingface.co](https://huggingface.co/settings/tokens) |

---

## ğŸ› ï¸ How It Works

1. User enters their API key from any supported provider in the sidebar.
2. The model list is dynamically shown or a custom model can be manually entered.
3. User types messages in a fixed input box at the bottom of the screen.
4. The chat history appears above in a live conversation layout.
5. Users can export chat logs, clear them, or copy individual responses.

---

## ğŸ’¡ Prompt Guide Included

The app includes a **Prompt Engineering tab** with curated templates for:
- Writing help
- Code generation
- Content summarization
- Use-case specific guidance

---

## ğŸ”’ Security & Privacy

- No API keys or inputs are logged or stored.
- All interactions are contained in the browser session.
- Built using **Streamlit** for UI simplicity and transparency.

---

## ğŸ“ Folder Structure

```bash
â”œâ”€â”€ app.py                  # Main Streamlit UI
â”œâ”€â”€ llm_handler.py          # LLM abstraction logic (OpenAI, OpenRouter, HuggingFace)
â”œâ”€â”€ utils.py                # Prompt templates and helpers
â”œâ”€â”€ requirements.txt        # All required Python packages
â””â”€â”€ README.md               # Youâ€™re here
```
---

##  ğŸ“¦ Installation & Setup

# Step 1: Clone the repo
```bash
git clone https://github.com/your-username/llm-chatbot-app.git
cd llm-chatbot-app
```

# Step 2: Create a virtual environment
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

# Step 3: Install dependencies
```bash
pip install -r requirements.txt
```

# Step 4: Run the app
```bash
streamlit run app.py
```

----

## ğŸ“Œ Why This Project Matters

This project demonstrates:

- Proficiency in working with LLMs, APIs, and frontend integration

- Design of provider-agnostic architecture (extendable to Cohere, Anthropic, etc.)

- Clean UI/UX using Streamlit with real-time interaction handling

- Readiness for enterprise applications in AI customer service, support bots, or developer assistants

---
## ğŸ‘¨â€ğŸ’» Built By

**Ranjith Kumar Surineni**  
_Data Scientist & AI Engineer_

- ğŸ”— [GitHub](https://github.com/ranjithsurineni)
- ğŸ’¼ [LinkedIn](https://www.linkedin.com/in/ranjithsurineni)
- ğŸ“§ [Email](mailto:ranjithsurineni.official@gmail.com)


"Designed with scalability and production-readiness in mind â€” ready for deployment in B2B/B2C LLM tools and client solutions."
